% Single laser work
\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage[pdftex]{graphicx} % for \includegraphics[scale=•]{•}
\usepackage{color}
\usepackage{pgf}


\begin{document}
\title{[DRAFT] - Stage Oriented Design of an Intersection Management System Based on Laser Scanner Data}

\author{Gustavo Velasco-Hernandez, Eduardo Caicedo-Bravo \\
Universidad del Valle\\
{\tt\small velasco.gustavo@correounivalle.edu.co, eduardo.caicedo@correounivalle.edu.co}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
}

\maketitle

\begin{abstract}
The supervision of vehicular intersections is a major need for improving transportation systems because these are complex scenarios where different traffic elements interact between them. Recently, laser-based systems have been proposed and implemented to sense and to monitor intersections, giving good results as those based on cameras. In this work a stage-oriented design of an intersection management system based on laserscanner sensor data is proposed. The main objective of the proposed architecture is that it should have scalability, modularity, and high integrability. In order to achieve those objectives, the process flow of an intersection management system (IMS) is divided into four stages: preprocessing, feature analysis, pattern recognition, and situation assessment. Each of these stages is explained and some commonly used techniques are described. Finally, we present an example implementation using a laserscanner dataset, both in a single-laser approach and a multi-laser approach.

\end{abstract}


\section{Introduction}

In transportation systems one of the most desirable scenarios to improve efficiency and safety are intersections. This because intersections are places where vehicles arrive from different directions at different velocities, increasing the chances for incidents and crashes. Choi \cite{Choi2010} states that 40\% of reported traffic accidents in the US, were intersection related. Also, in  \cite{CorporacionFondodePrevencionVial2010}, is reported that for Colombia in 2011, most of the accidents in the main cities were at intersections.

Several approaches for monitoring intersections are based on sensors on infrastructure like inductive loops, range scanners and cameras. Inductive loops detects presence of vehicles, which is simple for processing but information that could be extracted from they is limited. Cameras, on the other side, offer a high volume of data, but their processing requirements are high for extracting information. Range scanners are an intermediate option in which data from them is much high than from inductive loops, but not as high as from cameras and processing techniques for range data are not computational expensive as those for treating images or videos.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.8]{fig/carReferenceSystem.png}
\caption{Vehicle reference coordinate system}
\label{vehicle_cs}
\end{figure}

For range-based traffic monitoring systems there are three commonly used reference coordinate system for vehicles (Figure \ref{vehicle_cs}). Based on this, several laser-based systems have been proposed taking a plane as the main plane for laser scanner positioning. For example, F{\"u}erstenberg in  \cite{Fuerstenberg2000} proposes the use XZ plane scanning for vehicle classification and scanning on YZ plane for vehicle counting. Related to YZ plane, \cite{Harlow2001} and \cite{Vivet2013} present a deployment for vehicle monitoring scanning from the top and Gómez in \cite{Gomez2013} presents a side-view scanning for vehicle classification fused with a vision system. In \cite{Goldhammer2012} and \cite{Strigel2014}, Goldhammer and Striegel, respectively, detail an implemetation using a set of multilayer laser scanners deployed in different configurations for scanning from the top of the road, some using YZ plane and some using XZ plane. Recently, the use of XY plane has increased, and two main approaches arise: on-road and on-board systems. On-road systems are installed in infrastructure, aiming to detect passing vehicles, while on-board systems are installed on vehicles to detect the sourrounding environment. Both of them take the XY plane as main plane for scanning. Some examples of on-road sytems could be found in \cite{Zhao2006, Zhao2008, Zhao2009, Zhao2012} and \cite{Perng2014}. Petrovskaya in \cite{Petrovskaya2009} presents an On-board implementation.

All of the previous developments share a common processing stages that could be enumarated: preprocessing, feature analysis, pattern recognition, and situation assessment. In the section 2, these stages are explained and some common processing substages for each one are introduced. In section 3 is presented an example implementation based on a dataset and showing some methods and techniques used in the proposed stages. Section 4 presents the result of a single-laser and a multi-laser deployments. Finally, in section 6 are summarized the conclusions and some future work perspectives are proposed.



\section{Stages Definition}
In the designing of an IMS, there are four main stages that have to be performed from the data source to final output: preprocessing, feature analysis, pattern recognition and situation assessment.

The aim of the first stage is to extract data of interest from the raw sensor information, using filtering and background subtraction techniques to get the foreground of the scene, remove noise and irrelevant data. Spatio-temporal alignment of data is also performed in this stage. In the second stage, the objective is to identify elements within the foreground and extract relevant features of them. The third stage receives the set of features from the previous stage and performs recognition and classification tasks. Also, tracking and prediction of objects' state is performed based on historic information. In the fourth stage, object behaviour and inter-objects interaction are analysed to identify context and detect situation or events of interest.

The output of the fourth stage could be delivered to an optional fifth stage of decision and control, to a human operator, or to a traffic agent or institution, to take immediate actions on traffic control, issue traffic tickets, warn drivers about possible incidents or improve transportation policies in a long-term basis. In figure \ref{proc_stages}, previously described stages are depicted, and also is shown how the data volume is reduced while data meaning increases in the last stages.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.35]{../fig/3/proc_stages.png}
\caption{Dataflow through processing stages in an IMS.}
\label{proc_stages}
\end{figure}

Different tasks could be performed in each aforementioned stages, as is referred in figure \ref{proc_stages_tasks}. Below there is a description of common concepts and techniques associated with each of these tasks.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.35]{../fig/3/processing_stages_and_tasks.png}
\caption{Processing stages and tasks performed.}
\label{proc_stages_tasks}
\end{figure}
\subsection{Preprocessing}

 In the preprocessing stage raw data from sensor is received and the purpose is to enhance this data through filtering, removing noise and discarding corrupted data. Also, space and time alignment is done in this stage.

\subsubsection{Background Removing}
 
In order to extract meaningful information, background removal techniques are applied in this stage. For doing this, a background model should be generated. One typical approach to generate a background model is to use a threshold to determine if certain measure corresponds to background or foreground. This threshold is computed based on a peak value found in histogram of the measure within a time window. Another approach consist in describe the data using a probability distribution function, using maximum likelihood estimation, commonly of a gaussian model.
 
Sometimes, the threshold technique is enough for modeling static backgrounds like walls, buildings or ground. But in other cases, it could be found a non-stable background, for example, when there exist moving vegetation or object borders, and a mixture of models may retrieve a better representation of the data instead.

\subsubsection{Space and Time alignment}

In some cases, it could be desired to have a fixed base of time for trigger sensor readings, for synchronisation purposes or for implement fusion between different sensors within a time slot. It is for this reason that time alignment of data is done.

On the other side, in the case of laser scanners, the measures are referenced to its own coordinate systems. Calibration is needed to transform those measures to a global coordinate systems which represents the whole intersection scenario. 

\subsection{Feature Analysis}

After obtaining the foreground of the scene, it is needed to extract relevant points that could represent elements of interest in the intersection, like vehicles, pedestrians or obstacles. In this stage clustering is used to group points that belong to the same object, and for the nature of the environment, algorithms where estimated number of cluster is not needed are prefered. 


\subsection{Pattern Recognition}

From the previous stage we have a set of blobs as result of clustering, and based on the features of those blobs, different classes of objects could be recognized. Different classification types are implemented depending on the type of application, binary classification or multiclass classification.

When objects are identified, some relations between objects should be extracted to get more information about the scene. Relations between objects of the same class, objects of different classes or objects and environment are possible, both in a single timeslot or in sucesive timeslots. 

\subsection{Situation Assesment}

-TODO-

\section{Laser-based System Implementation}

\subsection{Dataset}
 The dataset used for this work was provided by POSS research group and was used for \cite{Zhao2009}. The dataset consist of ten minutes of laser scanner raw data from six sensors arranged horizontally over an intersection near Peking University. Background model and calibration data for each laser scanner is also provided. Additionally, dataset contains trajectory info of objects in the scene, generated by their algorithm. Figure \ref{inter_cfg} show intersection scenario, indicating position and orientation of each laser scanner inlcuded in dataset.

\begin{figure}
    \centering
    \input{fig/intersection-config2.pgf}
    \caption{System setup}
    \label{inter_cfg}
\end{figure}
 

 
\subsection{Preprocessing}

As mentioned before, the dataset provides a background model for each laser scanner. This model was generated using a histogram of each sampling angle of scanning, then a peak is found indicating a motionless object, considered as background. With the peak values at all sampling angles the background model is obtained. Now, when a new frame comes from the laser scanner, the measure at certain angle is compared with the peak value associated with that angle. If the difference is larger than a given threshold, the measured value is considered to belong to a moving object at the intersection. In figure \ref{bg_proc} is described the background removal process.



\begin{figure}[ht!]
\centering

\input{fig/bg_process.tex}
\caption{Example of background removal applied to frame 123 from laser scanner 2 of dataset. In the upper plot, the raw data from the laser scanner is depicted. In the lower plot, red points represent the background model estimated based on peak values of the histogram. Black points are those marked as foreground after comparison of raw data with background data. The threshold used was 20. (Axis in centimeters).}
\label{bg_proc}
\end{figure}


\subsection{Feature Analysis}

Clustering is performed on the foreground extracted to identify the set of points belonging to the same object. The algorithm used in this implementation is DBSCAN, which stands for Density-Based Spatial Clustering of Applications with Noise. This algorithm does not need an estimated number of clusters as input, instead of this, it requires only two parameters: a minimum number of points per cluster, m, and a neighbourhood measure, $\epsilon$. A detailed description of the algorithm, can be found in \cite{Ester96}.

\subsection{Pattern Recognition}

At this stage, a bounding box is computed for each cluster found in previous stage. Them, the area and center of the bounding box are calculated and this is stored as a Blob entity. Now, blob information and scen model are analyzed in order to get more knowledge about how are blobs distributed over the legs of intersection.

\subsection{Situation Assesment}

-TODO-

\section{Results}

Three different scene configurations were defined in order to test the system proposal: using a single laser scanner, using three laser scanners and another with all the six laser scanners available in the dataset.


\subsection{Scene 1: Single laser scanner}

For this configuration laser scanner LMS2 is chosen because it has a good coverage of intersection and leg 2.

\subsection{Scene 2: Three laser scanners}

In this configuration selected laser scanners are LMS1, LMS2 and LMS3 trying to have a general coverage of the intersection from different views

\subsection{Scene 3: Six laser scanners}
This configuration uses all the available laser from the dataset.

\section{Conclusions and Future Work}

-TODO-

{\small
\bibliographystyle{unsrt}
\bibliography{../bibliography}
}

\end{document}